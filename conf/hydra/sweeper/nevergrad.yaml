hydra:
  sweeper:
    params:
      optim:
        # name of the nevergrad optimizer to use
        # OnePlusOne is good at low budget, but may converge early
        optimizer: OnePlusOne
        # total number of function evaluations to perform
        budget: 100
        # number of parallel workers for performing function evaluations
        num_workers: 10
        # maximize: true  # comment out for maximization
      # default parametrization of the search space
      parametrization:
        # either one or the other
        model.db:
          - mnist
          - cifar
        # a log-distributed positive scalar, evolving by factors of 2 on average
        model.lr:
          init: 0.02
          step: 2.0
          log: true
        # an integer scalar going from 4 to 16
        # init and step parameters could also be provided,
        # by default init is set to the middle of the range
        # and step is set to a sixth of the range
        model.batch_size:
          lower: 4
          upper: 16
          integer: true
        # a custom nevergrad parameter evaluated at runtime (avoid using this whenever possible)
        model.dropout: Scalar(lower=0.0, upper=1.0)
